services:
  ollama:
    image: ollama/ollama:latest
    container_name: denuncias_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "ollama list > /dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 20
      start_period: 90s

  web:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: denuncias_web
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=development
      - OLLAMA_URL=http://ollama:11434
    depends_on:
      ollama:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  ollama-setup:
    image: curlimages/curl:latest
    container_name: denuncias_ollama_setup
    depends_on:
      ollama:
        condition: service_healthy
    command: >
      sh -c "
        echo 'üîÑ Aguardando Ollama ficar totalmente pronto...'
        sleep 10
        echo 'üìã Verificando modelos dispon√≠veis...'
        curl -s http://ollama:11434/api/tags | grep -q 'llama3.2:1b' && MODEL_EXISTS=true || MODEL_EXISTS=false
        if [ \"$$MODEL_EXISTS\" = \"false\" ]; then
          echo '‚¨áÔ∏è  Baixando modelo llama3.2:1b (isso pode demorar)...'
          curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"llama3.2:1b\"}'
          echo ''
          echo '‚úÖ Modelo baixado com sucesso!'
        else
          echo '‚úÖ Modelo llama3.2:1b j√° existe'
        fi
        echo 'üéâ Setup conclu√≠do!'
      "
    restart: "no"

volumes:
  ollama_data: